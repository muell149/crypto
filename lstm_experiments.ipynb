{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from collections import deque\n",
    "import random\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test read some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"crypto_data/LTC-USD.csv\", names=['time', 'low', 'high', 'open', 'close', 'volume'])\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define some global vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 60 #num mintutes of input sequence\n",
    "FUTURE_PERIOD_PREDICT = 3\n",
    "RATIO_TO_PREDICT = \"LTC-USD\"\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "NAME = f\"{SEQ_LEN}--SEQ--{FUTURE_PERIOD_PREDICT}--PRED--{int(time.time())}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(current,future):\n",
    "    ####\n",
    "    # create class labels\n",
    "    ####\n",
    "    if float(future) > float(current):\n",
    "        #buy\n",
    "        return 1\n",
    "    else:\n",
    "        #don't buy/sell\n",
    "        return 0\n",
    "    \n",
    "def preprocess_df(df):\n",
    "    #####\n",
    "    # normalize data\n",
    "    #####\n",
    "    \n",
    "    df = df.drop('future',1)\n",
    "    for col in df.columns:\n",
    "        if col != 'target':\n",
    "            df[col] = df[col].pct_change() #convert prices to pct change from previous value\n",
    "            df.dropna(inplace=True)\n",
    "            df[col] = preprocessing.scale(df[col].values) #normalize\n",
    "            \n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    sequential_data = []\n",
    "    prev_days = deque(maxlen=SEQ_LEN)\n",
    "\n",
    "    for row in df.values:\n",
    "        targ = row[-1]\n",
    "        feats = row[:-1]\n",
    "        \n",
    "        #-1 omits target col\n",
    "        prev_days.append([col for col in feats])\n",
    "        if len(prev_days) == SEQ_LEN:\n",
    "            sequential_data.append([np.array(prev_days), targ])\n",
    "            \n",
    "    random.shuffle(sequential_data)\n",
    "    \n",
    "    buys = []\n",
    "    sells = []\n",
    "    \n",
    "    for seq, target in sequential_data:\n",
    "        if target == 0:\n",
    "            sells.append([seq,target])\n",
    "        elif target == 1:\n",
    "            buys.append([seq,target])\n",
    "            \n",
    "    #shuffle orderings\n",
    "    random.shuffle(buys)\n",
    "    random.shuffle(sells)\n",
    "    \n",
    "    lower = min(len(buys), len(sells))\n",
    "    \n",
    "    #balance training data with equal class populations\n",
    "    buys=buys[:lower]\n",
    "    sells = sells[:lower]\n",
    "    \n",
    "    sequential_data = buys+sells\n",
    "    \n",
    "    #shuffle so it's not [buy1,buy2,...,buyN,sells1,sells2,sells3,..sellsN]\n",
    "    random.shuffle(sequential_data)\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for seq,target in sequential_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "        \n",
    "    return np.array(X), y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTC-USD\n",
      "LTC-USD\n",
      "BCH-USD\n",
      "ETH-USD\n",
      "            BTC-USD_close  BTC-USD_volume  LTC-USD_close  LTC-USD_volume  \\\n",
      "time                                                                       \n",
      "1528968720    6487.379883        7.706374      96.660004      314.387024   \n",
      "1528968780    6479.410156        3.088252      96.570000       77.129799   \n",
      "1528968840    6479.410156        1.404100      96.500000        7.216067   \n",
      "1528968900    6479.979980        0.753000      96.389999      524.539978   \n",
      "1528968960    6480.000000        1.490900      96.519997       16.991997   \n",
      "\n",
      "            BCH-USD_close  BCH-USD_volume  ETH-USD_close  ETH-USD_volume  \n",
      "time                                                                      \n",
      "1528968720     870.859985       26.856577      486.01001       26.019083  \n",
      "1528968780     870.099976        1.124300      486.00000        8.449400  \n",
      "1528968840     870.789978        1.749862      485.75000       26.994646  \n",
      "1528968900     870.000000        1.680500      486.00000       77.355759  \n",
      "1528968960     869.989990        1.669014      486.00000        7.503300  \n"
     ]
    }
   ],
   "source": [
    "main_df = pd.DataFrame() # begin empty\n",
    "\n",
    "ratios = [\"BTC-USD\", \"LTC-USD\", \"BCH-USD\", \"ETH-USD\"]  # the 4 files we want to consider\n",
    "for ratio in ratios:  # begin iteration\n",
    "    print(ratio)\n",
    "    dataset = f'crypto_data/{ratio}.csv'  # get the full path to the file.\n",
    "    df = pd.read_csv(dataset, names=['time', 'low', 'high', 'open', 'close', 'volume'])  # read in specific file\n",
    "\n",
    "    # rename volume and close to include the ticker so we can still which close/volume is which:\n",
    "    df.rename(columns={\"close\": f\"{ratio}_close\", \"volume\": f\"{ratio}_volume\"}, inplace=True)\n",
    "\n",
    "    df.set_index(\"time\", inplace=True)  # set time as index so we can join them on this shared time\n",
    "    df = df[[f\"{ratio}_close\", f\"{ratio}_volume\"]]  # ignore the other columns besides price and volume\n",
    "\n",
    "    if len(main_df)==0:  # if the dataframe is empty\n",
    "        main_df = df  # then it's just the current df\n",
    "    else:  # otherwise, join this data to the main one\n",
    "        main_df = main_df.join(df)\n",
    "\n",
    "main_df.fillna(method=\"ffill\", inplace=True)  # if there are gaps in data, use previously known values\n",
    "main_df.dropna(inplace=True)\n",
    "print(main_df.head())  # how did we do??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            LTC-USD_close     future\n",
      "time                                \n",
      "1528968720      96.660004  96.389999\n",
      "1528968780      96.570000  96.519997\n",
      "1528968840      96.500000  96.440002\n",
      "1528968900      96.389999  96.470001\n",
      "1528968960      96.519997  96.400002\n",
      "            LTC-USD_close     future  target\n",
      "time                                        \n",
      "1528968720      96.660004  96.389999       0\n",
      "1528968780      96.570000  96.519997       0\n",
      "1528968840      96.500000  96.440002       0\n",
      "1528968900      96.389999  96.470001       1\n",
      "1528968960      96.519997  96.400002       0\n",
      "1528969020      96.440002  96.400002       0\n",
      "1528969080      96.470001  96.400002       0\n",
      "1528969140      96.400002  96.400002       0\n",
      "1528969200      96.400002  96.400002       0\n",
      "1528969260      96.400002  96.449997       1\n"
     ]
    }
   ],
   "source": [
    "#set future targets\n",
    "main_df['future'] = main_df[f\"{RATIO_TO_PREDICT}_close\"].shift(-FUTURE_PERIOD_PREDICT)\n",
    "\n",
    "#sanity check to be sure our 'future' column (ML target), is indeed FUTURE_PERIOD_PREDICT time steps ahead in the sequence\n",
    "print(main_df[[f\"{RATIO_TO_PREDICT}_close\",\"future\"]].head())\n",
    "\n",
    "#Use classify function to set explicit target classification column. \n",
    "#Target = 1 when we should buy ie future value FUTURE_PERIOD_PREDICT steps ahead is higher than current value, target = 0 when same or lower\n",
    "main_df['target'] = list(map(classify, main_df[f\"{RATIO_TO_PREDICT}_close\"],main_df['future']))\n",
    "\n",
    "print(main_df[[f\"{RATIO_TO_PREDICT}_close\",\"future\",\"target\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train/test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = sorted(main_df.index.values)\n",
    "last_5pct = times[-int(0.05*len(times))]\n",
    "\n",
    "#split \n",
    "validation_main_df = main_df[(main_df.index >= last_5pct)]\n",
    "main_df = main_df[(main_df.index < last_5pct)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data feat size: 77922 validation: 3860\n",
      "[training]:: Don't buys: 38961 buys: 38961\n",
      "[testing]:: Don't buys: 1930 buys: 1930\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = preprocess_df(main_df)\n",
    "validation_x, validation_y = preprocess_df(validation_main_df)\n",
    "\n",
    "print(f\"train data feat size: {len(train_x)} validation: {len(validation_x)}\")\n",
    "print(f\"[training]:: Don't buys: {train_y.count(0)} buys: {train_y.count(1)}\")\n",
    "print(f\"[testing]:: Don't buys: {validation_y.count(0)} buys: {validation_y.count(1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_x))\n",
    "print(type(np.asarray(train_y)))\n",
    "print(type(validation_x))\n",
    "print(type(validation_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128,input_shape=(train_x.shape[1:]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(lr=0.001,decay=1e-6)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer=opt,\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1218/1218 [==============================] - ETA: 0s - loss: 0.6900 - accuracy: 0.5336WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: models/RNN_Final-01-0.569.model/assets\n",
      "1218/1218 [==============================] - 193s 158ms/step - loss: 0.6900 - accuracy: 0.5336 - val_loss: 0.6847 - val_accuracy: 0.5692\n",
      "Epoch 2/10\n",
      "1218/1218 [==============================] - ETA: 0s - loss: 0.6852 - accuracy: 0.5544INFO:tensorflow:Assets written to: models/RNN_Final-02-0.568.model/assets\n",
      "1218/1218 [==============================] - 199s 163ms/step - loss: 0.6852 - accuracy: 0.5544 - val_loss: 0.6750 - val_accuracy: 0.5679\n",
      "Epoch 3/10\n",
      "1218/1218 [==============================] - ETA: 0s - loss: 0.6826 - accuracy: 0.5619INFO:tensorflow:Assets written to: models/RNN_Final-03-0.534.model/assets\n",
      "1218/1218 [==============================] - 196s 161ms/step - loss: 0.6826 - accuracy: 0.5619 - val_loss: 0.6873 - val_accuracy: 0.5337\n",
      "Epoch 4/10\n",
      "1218/1218 [==============================] - ETA: 0s - loss: 0.6903 - accuracy: 0.5191INFO:tensorflow:Assets written to: models/RNN_Final-04-0.500.model/assets\n",
      "1218/1218 [==============================] - 195s 160ms/step - loss: 0.6903 - accuracy: 0.5191 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "1218/1218 [==============================] - ETA: 0s - loss: 0.6913 - accuracy: 0.5238INFO:tensorflow:Assets written to: models/RNN_Final-05-0.565.model/assets\n",
      "1218/1218 [==============================] - 187s 154ms/step - loss: 0.6913 - accuracy: 0.5238 - val_loss: 0.6814 - val_accuracy: 0.5648\n",
      "Epoch 6/10\n",
      "1218/1218 [==============================] - ETA: 0s - loss: 0.6876 - accuracy: 0.5471INFO:tensorflow:Assets written to: models/RNN_Final-06-0.545.model/assets\n",
      "1218/1218 [==============================] - 181s 148ms/step - loss: 0.6876 - accuracy: 0.5471 - val_loss: 0.6918 - val_accuracy: 0.5446\n",
      "Epoch 7/10\n",
      "1218/1218 [==============================] - ETA: 0s - loss: 0.6856 - accuracy: 0.5556INFO:tensorflow:Assets written to: models/RNN_Final-07-0.555.model/assets\n",
      "1218/1218 [==============================] - 189s 155ms/step - loss: 0.6856 - accuracy: 0.5556 - val_loss: 0.6852 - val_accuracy: 0.5549\n",
      "Epoch 8/10\n",
      "1218/1218 [==============================] - ETA: 0s - loss: 0.6841 - accuracy: 0.5588INFO:tensorflow:Assets written to: models/RNN_Final-08-0.554.model/assets\n",
      "1218/1218 [==============================] - 184s 151ms/step - loss: 0.6841 - accuracy: 0.5588 - val_loss: 0.6822 - val_accuracy: 0.5539\n",
      "Epoch 9/10\n",
      "1218/1218 [==============================] - ETA: 0s - loss: 0.6849 - accuracy: 0.5557INFO:tensorflow:Assets written to: models/RNN_Final-09-0.573.model/assets\n",
      "1218/1218 [==============================] - 204s 167ms/step - loss: 0.6849 - accuracy: 0.5557 - val_loss: 0.6790 - val_accuracy: 0.5725\n",
      "Epoch 10/10\n",
      "1218/1218 [==============================] - ETA: 0s - loss: 0.6818 - accuracy: 0.5628INFO:tensorflow:Assets written to: models/RNN_Final-10-0.565.model/assets\n",
      "1218/1218 [==============================] - 189s 156ms/step - loss: 0.6818 - accuracy: 0.5628 - val_loss: 0.6762 - val_accuracy: 0.5645\n"
     ]
    }
   ],
   "source": [
    "tensorboard = TensorBoard(log_dir=f'logs/{NAME}')\n",
    "filepath = \"RNN_Final-{epoch:02d}-{val_accuracy:.3f}\"\n",
    "checkpoint = ModelCheckpoint(\"models/{}.model\".format(filepath,monitor='val_accuracy',verbose=1,save_best_only=True,mode='max'))\n",
    "\n",
    "history = model.fit(\n",
    "    train_x, np.asarray(train_y),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(validation_x, np.asarray(validation_y)),\n",
    "    callbacks=[tensorboard,checkpoint],\n",
    ")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.6761615872383118\n",
      "Test accuracy: 0.564507782459259\n",
      "INFO:tensorflow:Assets written to: models/60--SEQ--3--PRED--1606761152/assets\n"
     ]
    }
   ],
   "source": [
    "# Score model\n",
    "score = model.evaluate(validation_x, np.asarray(validation_y), verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "# Save model\n",
    "model.save(\"models/{}\".format(NAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1130 13:35:08.832581 123145366757376 plugin_event_accumulator.py:322] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.4.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
